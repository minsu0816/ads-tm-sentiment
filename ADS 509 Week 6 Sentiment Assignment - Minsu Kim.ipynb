{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "data_location = \"C:/Users/suemi/Downloads/M1 Results/\"\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3090d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_files = {'cher':'cher_followers_data.txt',\n",
    "                'robyn':'robynkonichiwa_followers_data.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa61ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = []\n",
    "songs = [] \n",
    "lyrics = []\n",
    "\n",
    "for item in os.listdir(data_location + lyrics_folder) : \n",
    "    if os.path.isdir(data_location + lyrics_folder + item) :\n",
    "        for lyric_page in os.listdir(data_location + lyrics_folder + item) :\n",
    "            artist,song = lyric_page.split(\"_\")\n",
    "            \n",
    "            song = song.replace(\".txt\",\"\")\n",
    "\n",
    "            artists.append(artist)\n",
    "            songs.append(song)\n",
    "            \n",
    "            with open(data_location + lyrics_folder + item + \"/\" + lyric_page) as infile : \n",
    "                next(infile) # skip title\n",
    "                next(infile) # skip blank\n",
    "                next(infile) # skip blank\n",
    "                next(infile) # skip final blank\n",
    "                \n",
    "                lyrics.append(infile.read())\n",
    "        \n",
    "\n",
    "lyrics_data = pd.DataFrame()\n",
    "lyrics_data['artist'] = artists\n",
    "lyrics_data['song'] = songs\n",
    "lyrics_data['lyrics'] = lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163abbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = pd.read_csv(data_location + twitter_folder + artist_files['cher'],\n",
    "                           sep=\"\\t\",\n",
    "                           quoting=3)\n",
    "\n",
    "twitter_data['artist'] = \"cher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3850c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data_2 = pd.read_csv(data_location + twitter_folder + artist_files['robyn'],\n",
    "                             sep=\"\\t\",\n",
    "                             quoting=3)\n",
    "twitter_data_2['artist'] = \"robyn\"\n",
    "\n",
    "twitter_data = pd.concat([\n",
    "    twitter_data,twitter_data_2])\n",
    "    \n",
    "del(twitter_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "163bd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how I intially read the positive and negative data, into dataframes\n",
    "\n",
    "positive_words = pd.read_csv('positive-words.txt', comment=';', header=None, names=['word'])\n",
    "negative_words = pd.read_csv('negative-words.txt', comment=';', header=None, names=['word'])\n",
    "tidytext = pd.read_csv('tidytext_sentiments.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c47d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lexicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  sentiment lexicon\n",
       "0     2-faced         -1     NaN\n",
       "1     2-faces         -1     NaN\n",
       "2    abnormal         -1     NaN\n",
       "3     abolish         -1     NaN\n",
       "4  abominable         -1     NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidytext_df = tidytext\n",
    "tidytext_df['sentiment'] = tidytext_df['sentiment'].replace({'positive': 1, 'negative': -1})\n",
    "tidytext_df = pd.concat([positive_words.assign(sentiment=1), tidytext_df])\n",
    "tidytext_df = pd.concat([negative_words.assign(sentiment=-1), tidytext_df])\n",
    "tidytext_df = tidytext_df.drop_duplicates(subset='word')\n",
    "\n",
    "tidytext_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "553636a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-faced</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-faces</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abolish</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  sentiment\n",
       "0     2-faced         -1\n",
       "1     2-faces         -1\n",
       "2    abnormal         -1\n",
       "3     abolish         -1\n",
       "4  abominable         -1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidytext_df = tidytext_df.drop('lexicon', axis=1)\n",
    "tidytext_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081cbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then it was difficult to proceed with dataframes\n",
    "# office hours helped with getting the data into a dictonary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9e7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "sentiment = dict()\n",
    "\n",
    "with open(positive_words_file, 'r') as infile :\n",
    "    for idx, line in enumerate(infile.readlines()) :\n",
    "        if line[0] == \";\" :\n",
    "            continue\n",
    "            \n",
    "        line = line.strip()\n",
    "        \n",
    "        if line and line.isalpha() :\n",
    "            sentiment[line.strip()] = 1\n",
    "            \n",
    "with open(negative_words_file, 'r') as infile :\n",
    "    for idx, line in enumerate(infile.readlines()) :\n",
    "        if line[0] == \";\" :\n",
    "            continue\n",
    "            \n",
    "        line = line.strip()\n",
    "        \n",
    "        if line and line.isalpha() :\n",
    "            sentiment[line.strip()] = -1\n",
    "            \n",
    "            \n",
    "with open(tidy_text_file, 'r') as infile :\n",
    "    next(infile)\n",
    "    for line in infile.readlines() :\n",
    "        word, sent, lexicon = line.strip().split(\"\\t\")\n",
    "        \n",
    "        if sent == \"negative\" :\n",
    "            sentiment[word] = -1\n",
    "        elif sent == \"positive\" :\n",
    "            sentiment[word] = 1\n",
    "        else :\n",
    "            print(f\"Got {word} with sentiment {sentiment}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text,sent=sentiment) :\n",
    "    text = [w.lower() for w in text.split()]\n",
    "    \n",
    "    sentiment = sum([sent[word] for word in text if word in sent])\n",
    "    \n",
    "    return(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7421e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_data['sentiment'] = lyrics_data['lyrics'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913e9471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     5.955696\n",
       "robyn    7.644231\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sentiment = lyrics_data.groupby('artist')['sentiment'].mean()\n",
    "\n",
    "average_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4094ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_artist = lyrics_data[lyrics_data['artist'] == 'cher']\n",
    "\n",
    "sorted_by_sentiment = first_artist.sort_values(by='sentiment')\n",
    "\n",
    "top_3_songs = sorted_by_sentiment.tail(3)\n",
    "bottom_3_songs = sorted_by_sentiment.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51c0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>cher</td>\n",
       "      <td>perfection</td>\n",
       "      <td>Hush little Baby, gotta be strong\\n'Cause in t...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>cher</td>\n",
       "      <td>ifoundyoulove</td>\n",
       "      <td>Well I was looking for a new love, a different...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>cher</td>\n",
       "      <td>loveandunderstanding</td>\n",
       "      <td>Here, here in this world\\nWhere do we go? Wher...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                  song  \\\n",
       "198   cher            perfection   \n",
       "108   cher         ifoundyoulove   \n",
       "155   cher  loveandunderstanding   \n",
       "\n",
       "                                                lyrics  sentiment  \n",
       "198  Hush little Baby, gotta be strong\\n'Cause in t...         43  \n",
       "108  Well I was looking for a new love, a different...         51  \n",
       "155  Here, here in this world\\nWhere do we go? Wher...         56  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bc12de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cher</td>\n",
       "      <td>bangbang</td>\n",
       "      <td>Bang bang you shot me down\\nBang bang I hit th...</td>\n",
       "      <td>-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>cher</td>\n",
       "      <td>outrageous</td>\n",
       "      <td>Outrageous, outrageous\\n(They say) I'm outrage...</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>cher</td>\n",
       "      <td>iwalkonguildedsplinters</td>\n",
       "      <td>Some people think they jive me, but I know the...</td>\n",
       "      <td>-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                     song  \\\n",
       "16    cher                 bangbang   \n",
       "196   cher               outrageous   \n",
       "133   cher  iwalkonguildedsplinters   \n",
       "\n",
       "                                                lyrics  sentiment  \n",
       "16   Bang bang you shot me down\\nBang bang I hit th...        -70  \n",
       "196  Outrageous, outrageous\\n(They say) I'm outrage...        -26  \n",
       "133  Some people think they jive me, but I know the...        -24  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_3_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c47ae501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hush little Baby, gotta be strong\n",
      "'Cause in this world we are born to fight\n",
      "Be the best, prove them wrong\n",
      "A winner's work is never done, reach the top, number one\n",
      "\n",
      "Oh, perfection\n",
      "You drive me crazy with perfection\n",
      "I've worn my pride as my protection\n",
      "Perfection, ohh\n",
      "\n",
      "I was taught to be tough\n",
      "That the best that you can be ain't enough\n",
      "Crack the whip, sacrifice\n",
      "But I found out paradise had a price\n",
      "\n",
      "I didn't know it then, but oh I know it now\n",
      "You gotta work as hard as love to make the love work out\n",
      "You know this heart of mine has made some big mistakes\n",
      "I guess that when it comes to love, I just don't know what I takes\n",
      "\n",
      "All my life I've been driven by perfection\n",
      "Pushed it to the limit every day and night\n",
      "Ohh, I've been driven by perfection\n",
      "But nothing's perfect when love ain't right\n",
      "Nothing's perfect when the love ain't right\n",
      "\n",
      "Gave it all, played my part\n",
      "I gave everything I had but my heart\n",
      "Worked so hard, made a name\n",
      "But the loneliness inside stays the same\n",
      "\n",
      "When love is here today, and then it's gone today\n",
      "You got a list of lovers lookin' like a resume\n",
      "You gotta take some time to make it something real\n",
      "I guess that when it comes to love, I just don't know how to feel\n",
      "\n",
      "All my life I've been driven by perfection\n",
      "Pushed it to the limit every day and night\n",
      "Ohh, I've been driven by perfection\n",
      "But nothing's perfect when love ain't right\n",
      "Nothing's perfect when the love ain't right\n",
      "\n",
      "Oh, perfection\n",
      "You drive me crazy with perfection\n",
      "I've worn my pride as my protection\n",
      "I'm goin' crazy with perfection\n",
      "\n",
      "Ohh, I didn't know it then, but oh I know it now\n",
      "You gotta work as hard as love to make the love work out\n",
      "You know this heart of mine has made some big mistakes\n",
      "I guess that when it comes to love, I just don't know what I takes\n",
      "\n",
      "I've been driven by perfection\n",
      "Pushed it to the limit every day and night\n",
      "Ohh, I've been driven by perfection\n",
      "But nothing's perfect when love ain't right\n",
      "\n",
      "All my life I've been driven by perfection\n",
      "Pushed it to the limit every day and night\n",
      "Ohh, I've been driven by perfection\n",
      "But nothing's perfect when love ain't right\n",
      "\n",
      "All my life I've been driven by perfection\n",
      "Pushed it to the limit every day and night\n",
      "Ohh, I've been driven by perfection\n",
      "But nothing's perfect when love ain't right\n",
      "\n",
      "All my life I've been driven by perfection\n",
      "\n",
      "--------------------------------------------------\n",
      "Well I was looking for a new love, a different kind of true love\n",
      "Who's gonna treat me right, all day and night\n",
      "Hey baby I've been looking too\n",
      "And I have found there's\n",
      "No other love from me but you\n",
      "Well I was looking for a new love\n",
      "A different kind of true love\n",
      "Who's gonna treat me right\n",
      "Day and night\n",
      "Well I found what I was after\n",
      "Now my life is filled with laughter\n",
      "I found you love\n",
      "I was lost with no direction\n",
      "Then my life was one big question\n",
      "I was down and out\n",
      "Filled with doubt\n",
      "Found what I was after\n",
      "Now my life is filled with laughter\n",
      "I found you love\n",
      "I found you love\n",
      "I found a new love\n",
      "He's wonderful and true\n",
      "He's gonna spent his money\n",
      "He's gonna call me honey\n",
      "I gonna tease her\n",
      "Oh Lord, I gonna squeeze her\n",
      "Gonna love her plenty\n",
      "She's gonna make me manly\n",
      "We're gonna hold love while we can\n",
      "I've been looking for a new love\n",
      "A different kind of true love\n",
      "Who's gonna treat me right\n",
      "Every day and every night\n",
      "Now I found what I was after\n",
      "Now my life is filled with laughter\n",
      "I found you love\n",
      "I found you love\n",
      "I found a new love\n",
      "He's wonderful and true\n",
      "He's gonna spent his money\n",
      "He's gonna call me honey\n",
      "I gonna please her\n",
      "Oh Lord, I gonna squeeze her\n",
      "Gonna love me madly\n",
      "I'm gonna love her gladly\n",
      "We're gonna hold love while we can\n",
      "We're gonna hold love while we can\n",
      "\n",
      "--------------------------------------------------\n",
      "Here, here in this world\n",
      "Where do we go? Where can we turn?\n",
      "When we need some love\n",
      "It seems that love just can't be found\n",
      "Where, where do we stand?\n",
      "When love's supply don't meet love's demand\n",
      "\n",
      "We got enough stars to light the sky at night\n",
      "Enough sun to make to make the whole world bright\n",
      "We got more than enough\n",
      "But there's one thing there's just not enough of\n",
      "\n",
      "Not enough love and understanding\n",
      "We could use some love to ease these troubled times\n",
      "Not enough love and understanding\n",
      "Why, oh why?\n",
      "\n",
      "Spend all of our time\n",
      "Building buildings up to the sky\n",
      "Reaching everywhere\n",
      "But where we need to reach the most\n",
      "Hearts never can win\n",
      "Oh, in this race, this race that we're in\n",
      "\n",
      "We've got enough cars to drive around the world\n",
      "Enough planes to take us anywhere\n",
      "We got more than enough\n",
      "But there's one thing there's just not enough of\n",
      "\n",
      "Not enough love and understanding\n",
      "We could use some love to ease these troubled times\n",
      "Not enough love and understanding\n",
      "Why, oh why?\n",
      "\n",
      "Not enough love and understanding\n",
      "We could use some love to ease these troubled times\n",
      "Not enough love and understanding\n",
      "Why, oh why?\n",
      "\n",
      "We need some understandin'\n",
      "We need a little more love\n",
      "Some love and understandin'\n",
      "\n",
      "Enough stars to light the sky at night\n",
      "Enough sun to make the whole world bright\n",
      "Enough hearts to find some love inside\n",
      "We got more than enough\n",
      "But there's one thing there's just not enough of\n",
      "\n",
      "Not enough love and understanding\n",
      "We could use some love to ease these troubled times\n",
      "Not enough love and understanding\n",
      "Why, oh why?\n",
      "...\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Bang bang you shot me down\n",
      "Bang bang I hit the ground\n",
      "Bang bang that awful sound\n",
      "Bang bang my baby shot me down\n",
      "\n",
      "I was five and you were six\n",
      "We rode on horses made of sticks\n",
      "I wore black you wore white\n",
      "You would always win the fight\n",
      "\n",
      "Bang bang you shot me down\n",
      "Bang bang I hit the ground\n",
      "Bang bang that awful sound\n",
      "Bang bang my baby shot me down\n",
      "\n",
      "Seasons came and changed the time\n",
      "I grew up I called you mine\n",
      "You would always laugh and say\n",
      "Remember when we used to play\n",
      "\n",
      "Bang bang you shot me down\n",
      "Bang bang and I hit the ground\n",
      "Bang bang that awful sound\n",
      "Bang bang my baby shot me down\n",
      "\n",
      "Music played and people sang\n",
      "Just for me the church bells rang\n",
      "After echoes from a gun\n",
      "We both vowed that we'd be one\n",
      "\n",
      "Now you're gone I don't know why\n",
      "Sometimes I cry\n",
      "You didn't say goodbye\n",
      "You didn't take the time to lie\n",
      "\n",
      "Bang bang you shot me down\n",
      "Bang bang I hit the ground\n",
      "Bang bang that awful sound\n",
      "Bang bang my baby shot me down\n",
      "\n",
      "Bang bang you shot me right between my eyes\n",
      "Bang bang you can't go paralyzed\n",
      "Bang bang bang bang bang bang\n",
      "Bang bang oh baby I'm laying on the ground\n",
      "Bang bang I'll never come around\n",
      "\n",
      "Bang bang\n",
      "Bang bang\n",
      "Oh baby\n",
      "Bang bang\n",
      "Oh baby come and wrap me\n",
      "Bang bang\n",
      "You see how sweet it's gonna be\n",
      "\n",
      "Bang bang\n",
      "Bang bang\n",
      "Bang bang\n",
      "Oh my baby my baby shot me down\n",
      "Bang bang\n",
      "I'm up on the ground now\n",
      "\n",
      "--------------------------------------------------\n",
      "Outrageous, outrageous\n",
      "(They say) I'm outrageous\n",
      "It's the rage\n",
      "\n",
      "I'm gonna wear what I will and spend some\n",
      "And I will be dress to kill don'tcha know\n",
      "And when the lights come up\n",
      "I'm ready I'm ready\n",
      "To put on a show with class\n",
      "And if I clash it's cause I want to\n",
      "What a show and I want everyone to know\n",
      "They're gonna fly up, get an eyeful\n",
      "Everything that's craved from me\n",
      "I'm gonna be, I'm gonna be outrageous\n",
      "\n",
      "Outrageous\n",
      "(They say) I'm outrageous\n",
      "It's the rage it's the rage\n",
      "\n",
      "With my long black hair hanging way down to my\n",
      "Ask me no questions and I'll tell you no lies\n",
      "Don't tell me what to do don't tell me what to be\n",
      "See I don't trust anybody else's traits about make-up and me\n",
      "\n",
      "Well in my show I let everything go\n",
      "Is what you want is whatcha wanna see from me\n",
      "But when the curtain comes down\n",
      "And you're on your way back home\n",
      "I change into my jeans that are split at the seam\n",
      "I grab my funky black jacket and make quite a racket\n",
      "You drive like you're an outlaw\n",
      "Cause everything that's craved from me\n",
      "I'm gonna be, I'm gonna be outrageous\n",
      "\n",
      "So outrageous\n",
      "I'm outrageous honey yes a rage\n",
      "It's the rage\n",
      "Outrageous, outrageous\n",
      "I'm outrageous\n",
      "It's the rage it's a rage\n",
      "Outrageous, outrageous\n",
      "They say I'm outrageous\n",
      "\n",
      "--------------------------------------------------\n",
      "Some people think they jive me, but I know they must be crazy\n",
      "They can't see their misfortune, or else they're just too lazy\n",
      "Je suie le grand zombie\n",
      "With my yellow chaffen of choisen\n",
      "Ain't afraid of no tomcat and gonna fill my guts with poison\n",
      "I walk through the fire\n",
      "And I'll fly through the smoke\n",
      "I wanna see my enemies\n",
      "On the end of my rope\n",
      "Walk on pins and needles\n",
      "And I see what they can do\n",
      "Walk on guilded splinters\n",
      "With the King of the Zulu\n",
      "\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "\n",
      "When I roll out in my coffin\n",
      "Drink poison in my chalice\n",
      "Pride begins to fade\n",
      "And you all feel my malice\n",
      "I put gris-gris on your doorstep\n",
      "So soon you be in the gutter\n",
      "I'll make your heart melt like butter\n",
      "I say I can make you stutter\n",
      "\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Come to me, get it, come, come\n",
      "Walk on guilded splinters\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "Till I burn up\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# print lyrics\n",
    "for i, row in top_3_songs.iterrows():\n",
    "    print(row['lyrics'])\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "print(\"-\"*50)\n",
    "\n",
    "for i, row in bottom_3_songs.iterrows():\n",
    "    print(row['lyrics'])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c87fbd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>robyn</td>\n",
       "      <td>wedancetothebeat</td>\n",
       "      <td>We dance to the beat\\nWe dance to the beat\\nWe...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>robyn</td>\n",
       "      <td>wedancetothebeat114528</td>\n",
       "      <td>We dance to the beat\\nWe dance to the beat\\nWe...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>robyn</td>\n",
       "      <td>loveisfree</td>\n",
       "      <td>Free\\nLove is free, baby\\nFree\\nLove is free, ...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                    song  \\\n",
       "414  robyn        wedancetothebeat   \n",
       "415  robyn  wedancetothebeat114528   \n",
       "380  robyn              loveisfree   \n",
       "\n",
       "                                                lyrics  sentiment  \n",
       "414  We dance to the beat\\nWe dance to the beat\\nWe...         65  \n",
       "415  We dance to the beat\\nWe dance to the beat\\nWe...         65  \n",
       "380  Free\\nLove is free, baby\\nFree\\nLove is free, ...        116  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_artist = lyrics_data[lyrics_data['artist'] == 'robyn']\n",
    "\n",
    "sorted_by_sentiment2 = second_artist.sort_values(by='sentiment')\n",
    "\n",
    "top_3_songs1 = sorted_by_sentiment2.tail(3)\n",
    "bottom_3_songs1 = sorted_by_sentiment2.head(3)\n",
    "\n",
    "top_3_songs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69217d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>robyn</td>\n",
       "      <td>dontfuckingtellmewhattodo114520</td>\n",
       "      <td>My drinking is killing me\\nMy drinking is kill...</td>\n",
       "      <td>-92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>robyn</td>\n",
       "      <td>dontfuckingtellmewhattodo</td>\n",
       "      <td>My drinking is killing me\\nMy drinking is kill...</td>\n",
       "      <td>-92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>robyn</td>\n",
       "      <td>criminalintent</td>\n",
       "      <td>Somebody alert the authorities, I got criminal...</td>\n",
       "      <td>-53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                             song  \\\n",
       "343  robyn  dontfuckingtellmewhattodo114520   \n",
       "342  robyn        dontfuckingtellmewhattodo   \n",
       "334  robyn                   criminalintent   \n",
       "\n",
       "                                                lyrics  sentiment  \n",
       "343  My drinking is killing me\\nMy drinking is kill...        -92  \n",
       "342  My drinking is killing me\\nMy drinking is kill...        -92  \n",
       "334  Somebody alert the authorities, I got criminal...        -53  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_3_songs1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8334f4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Q: Overall, which artist has the higher average sentiment per song? \n",
    "\n",
    "A: Robyn\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your first artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: The highest and lowest sentiment songs are shown above; obviously, some of the extreme words are seen in the song title and lyrics which maybe driving the scores.\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your second artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: The highest and lowest sentiment songs are shown above, and I think the it's for the same reason mentioned in the previous question.\n",
    "\n",
    "---\n",
    "\n",
    "Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9de2e118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "robyn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lyrics_data.groupby('artist')['sentiment'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe644d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. You do not need to calculate sentiment on non-emoji content for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a5c1d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': 1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1,\n",
       " '': -1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_emojis = ['','','','','','','','','','','','','','','']\n",
    "negative_emojis = ['','','','','','','','','','','','','','','']\n",
    "\n",
    "emoji_sentiment = dict(zip(positive_emojis,[1]*15))\n",
    "emoji_sentiment.update(dict(zip(negative_emojis,[-1]*15)))\n",
    "\n",
    "emoji_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11768e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc_sentiment(desc,sent=emoji_sentiment) :\n",
    "    \n",
    "    sentiment = sum([sent[ch] for ch in str(desc) if ch in sent])\n",
    "    \n",
    "    return(sentiment)\n",
    "\n",
    "def extract_emojis(desc,emoji_list) :\n",
    "    emojis = [ch for ch in str(desc) if ch in emoji_list]\n",
    "    \n",
    "    return(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddb359eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_emojis() missing 1 required positional argument: 'emoji_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38252/2486498128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_desc_sentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_emoji'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_emojis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_desc_sentiment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg_emoji'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_emojis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_desc_sentiment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4628\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4629\u001b[0m         \"\"\"\n\u001b[1;32m-> 4630\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4632\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1077\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_emojis() missing 1 required positional argument: 'emoji_list'"
     ]
    }
   ],
   "source": [
    "twitter_data['sentiment'] = twitter_data.description.apply(get_desc_sentiment)\n",
    "twitter_data['pos_emoji'] = twitter_data.description.apply(extract_emojis,args=(get_desc_sentiment == 1))\n",
    "twitter_data['neg_emoji'] = twitter_data.description.apply(extract_emojis,args=(get_desc_sentiment == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "637315fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>KieraOsiecki</td>\n",
       "      <td>keezy</td>\n",
       "      <td>559655482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1229</td>\n",
       "      <td>623</td>\n",
       "      <td>welcome back </td>\n",
       "      <td>cher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Mimijnm</td>\n",
       "      <td>Memi3</td>\n",
       "      <td>845613602</td>\n",
       "      <td>Subn Chicago, USA</td>\n",
       "      <td>1383</td>\n",
       "      <td>3100</td>\n",
       "      <td>Love my country, grandkids and dogs! (husband ...</td>\n",
       "      <td>cher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Good_Person_111</td>\n",
       "      <td>I stand with Ukraine </td>\n",
       "      <td>1040097022307651589</td>\n",
       "      <td>Illinois, USA</td>\n",
       "      <td>38</td>\n",
       "      <td>111</td>\n",
       "      <td>Stand with Ukraine  Dans wife  Mollies mo...</td>\n",
       "      <td>cher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Sarah25Boussi</td>\n",
       "      <td>Sarah25</td>\n",
       "      <td>878738488061042689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td></td>\n",
       "      <td>cher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>VAAF07</td>\n",
       "      <td>Valentina</td>\n",
       "      <td>126409647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>578</td>\n",
       "      <td> Berlina </td>\n",
       "      <td>cher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         screen_name                     name                   id  \\\n",
       "110     KieraOsiecki                    keezy            559655482   \n",
       "182          Mimijnm                    Memi3            845613602   \n",
       "320  Good_Person_111  I stand with Ukraine   1040097022307651589   \n",
       "360    Sarah25Boussi                  Sarah25   878738488061042689   \n",
       "471           VAAF07                Valentina            126409647   \n",
       "\n",
       "              location  followers_count  friends_count  \\\n",
       "110                NaN             1229            623   \n",
       "182  Subn Chicago, USA             1383           3100   \n",
       "320      Illinois, USA               38            111   \n",
       "360                NaN                0            262   \n",
       "471                NaN              204            578   \n",
       "\n",
       "                                           description artist  sentiment  \n",
       "110                                     welcome back    cher          1  \n",
       "182  Love my country, grandkids and dogs! (husband ...   cher          1  \n",
       "320  Stand with Ukraine  Dans wife  Mollies mo...   cher          1  \n",
       "360                                                     cher          1  \n",
       "471                                      Berlina    cher          1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.query('sentiment > 0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d38dd0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>artist</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Mermarietho</td>\n",
       "      <td>Spoopy Jim </td>\n",
       "      <td>722620867507724288</td>\n",
       "      <td>Crack House</td>\n",
       "      <td>54</td>\n",
       "      <td>266</td>\n",
       "      <td>I just love my dog, man</td>\n",
       "      <td>cher</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>cyndeecexxx</td>\n",
       "      <td>cyndee cexxx</td>\n",
       "      <td>1502083138813575168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>87</td>\n",
       "      <td>communist cum dumpster. here to be shared by t...</td>\n",
       "      <td>cher</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>RussellDeer1</td>\n",
       "      <td>Russell Deer</td>\n",
       "      <td>1399742498923233281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>,</td>\n",
       "      <td>cher</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>portraitxmirage</td>\n",
       "      <td>ari mirage  | i cant be your only 1</td>\n",
       "      <td>1331255726468173827</td>\n",
       "      <td>the roof</td>\n",
       "      <td>1400</td>\n",
       "      <td>1356</td>\n",
       "      <td>just a small town girl tryna make it big || m...</td>\n",
       "      <td>cher</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>SABARBCHILE</td>\n",
       "      <td> Nicki </td>\n",
       "      <td>1390926049610018816</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "      <td>789</td>\n",
       "      <td>1087</td>\n",
       "      <td>It's them weak bars thinkin' that she dissin' ...</td>\n",
       "      <td>cher</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name                                   name  \\\n",
       "168       Mermarietho                           Spoopy Jim    \n",
       "1214      cyndeecexxx                           cyndee cexxx   \n",
       "1543     RussellDeer1                           Russell Deer   \n",
       "1750  portraitxmirage  ari mirage  | i cant be your only 1   \n",
       "1935      SABARBCHILE                               Nicki    \n",
       "\n",
       "                       id                 location  followers_count  \\\n",
       "168    722620867507724288              Crack House               54   \n",
       "1214  1502083138813575168                      NaN               57   \n",
       "1543  1399742498923233281                      NaN                2   \n",
       "1750  1331255726468173827                 the roof             1400   \n",
       "1935  1390926049610018816  Cape Town, South Africa              789   \n",
       "\n",
       "      friends_count                                        description artist  \\\n",
       "168             266                          I just love my dog, man   cher   \n",
       "1214             87  communist cum dumpster. here to be shared by t...   cher   \n",
       "1543             63                                          ,   cher   \n",
       "1750           1356  just a small town girl tryna make it big || m...   cher   \n",
       "1935           1087  It's them weak bars thinkin' that she dissin' ...   cher   \n",
       "\n",
       "      sentiment  \n",
       "168          -1  \n",
       "1214         -1  \n",
       "1543         -1  \n",
       "1750         -1  \n",
       "1935         -1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.query('sentiment < 0').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce918582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     0.008288\n",
       "robyn    0.003187\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.groupby('artist').sentiment.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df4fe7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_emojis(emoji_list, n=3):\n",
    "    emoji_count={}\n",
    "    for emoji in emoji_list:\n",
    "        if emoji in emoji_count:\n",
    "            emoji_count[emoji] += 1\n",
    "        else:\n",
    "            emoji_count[emoji] = 1\n",
    "    sorted_emojis = sorted(emoji_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_n_emojis = [emoji for emoji, count in sorted_emojis[:n]]\n",
    "    return top_n_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3692f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was unable to run this code due to not being able to extract 'pos_emoji' above\n",
    "## emojis_by_artist = twitter_data.groupby('artist')['pos_emoji'].apply(lambda x: groupby(twitter_data['artist']))\n",
    "## emojis_by_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92eb93",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists? \n",
    "\n",
    "A: 0.008 and 0.003\n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji? \n",
    "\n",
    "A: <\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
